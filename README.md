# **Transcribe Audio Service**

Transcribe Audio Service is a lightweight, standalone transcription tool for Windows that batch-converts audio files into readable text â€” no technical setup required.

Harnessing the full range of OpenAIâ€™s Whisper models, users can tailor transcription performance and accuracy to meet the needs of any task, from rapid summaries to detailed archival records.

Supported audio formats include .mp3, .m4a, .wav, .wma, .flac, .ogg, and .aac, providing robust compatibility for academic and enterprise use cases.

Users can choose between One Shot batch transcription or Continuous Directory Monitoring to automatically process new files at set intervals. Output formats include .txt, .csv, .json, and .xml, with optional translation to English for supported languages.

Version 1.4.0 introduces Automated Speaker Recognition, powered by Pyannoteâ€™s state-of-the-art diarization pipeline, enabling clearer attribution in multi-speaker environments.

Built with configurability and reliability in mind, this tool is ideal for professionals seeking accurate, flexible, and efficient audio transcription at scale.

---

ğŸš€ Features

    ğŸ–¥ï¸ Simple, standalone desktop app â€” no technical setup required

    ğŸ§  Intelligent UI Design â€” effortlessly manage, deploy, and monitor audio transcriptions through an intuitive interface

    ğŸ¤– Transcriptions powered by [OpenAIâ€™s Whisper](https://github.com/openai/whisper)** â€” select from all available models to balance speed, size, and accuracy

    ğŸ”Š Automated Speaker Recognition powered by [Pyannote-Audio](https://github.com/pyannote/pyannote-audio)** â€” automatically detects and assigns speaker labels 

    ğŸ§ Supports .mp3, .m4a, .wav, .wma, .flac, .ogg, and .aac audio formats

    ğŸŒ Optional Translate â†’ English â€” available for supported languages

    ğŸ”„ One Shot transcription or Continuous Directory Monitoring â€” batch process or watch folders at custom intervals

    ğŸ—‚ï¸ Multiple output formats â€” export transcripts as pre formatted .txt, .json, .csv, or .xml 

    ğŸ§¾ Rich transcript metadata â€” includes filename, creation date, duration, audio language, output language, and more

    ğŸ“‚ Click-to-open completed files â€” launch transcripts directly from the UI display

---

âš™ï¸ Getting Started (Run from Source)

1. Clone the repository
git clone https://github.com/yourname/transcribe-audio-service.git
cd transcribe-audio-service

2. Create Virtual environment
python -m venv venv
venv\Scripts\activate  # On Windows

3. Install dependencies
pip install -r requirements.txt

4. Run the app
python main.py

---

ğŸ“ Project Structure
<pre>

transcribe-audio-service/
â”‚
â”œâ”€â”€ main.py                         # Launches the GUI application
â”‚
â”œâ”€â”€ gui/                            # GUI components (modularized)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                      # Entry point for launching TranscribeAudioService
â”‚   â”œâ”€â”€ ui_main.py                  # Main layout and logic controller
â”‚   â”œâ”€â”€ service_controls.py         # Transcribe, Stop, and service status label
â”‚   â”œâ”€â”€ queue_display.py            # File queue, status indicators, and output box
â”‚   â”œâ”€â”€ settings_input.py           # Input settings frame (directory, language, monitoring)
â”‚   â”œâ”€â”€ settings_output.py          # Output settings frame (directory, format, translation)
â”‚   â”œâ”€â”€ settings_model.py           # Model settings frame (model selection + speaker toggle)
â”‚   â””â”€â”€ style_config.py             # Centralized style definitions (ttkbootstrap)
â”‚
â”œâ”€â”€ services/                       # Core services and business logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ constants.py                # Centralized constants (e.g., language map, supported extensions)
â”‚   â”œâ”€â”€ dependency_check.py         # Optional: verifies installed dependencies
â”‚   â”œâ”€â”€ template_manager.py         # Loads and injects templates for output formats
â”‚   â”œâ”€â”€ transcription.py            # Whisper transcription logic
â”‚   â”œâ”€â”€ utils_audio.py              # Audio utilities (format conversion, prep)
â”‚   â”œâ”€â”€ utils_transcribe.py         # Transcription utilities (device check, segmentation)
â”‚   â””â”€â”€ version.py                  # Application version constant
â”‚
â”œâ”€â”€ .models/                        # ğŸ”’(Git-ignored) Local cache for Whisper + Pyannote models
â”‚                                   # Automatically created/downloaded at runtime â€” not tracked in Git
â”‚
â”œâ”€â”€ cache_models/                   # ğŸ”’(Git-ignored) Helper scripts to pre-cache models
â”‚   â””â”€â”€ cache_pyannote_model.py     # Used to download and store diarization models locally
â”‚
â”œâ”€â”€ templates/                      # Output templates for various formats
â”‚   â”œâ”€â”€ transcript_template.csv
â”‚   â”œâ”€â”€ transcript_template.json
â”‚   â”œâ”€â”€ transcript_template.txt
â”‚   â””â”€â”€ transcript_template.xml


.gitignore
LICENSE
requirements.txt 
README.md
</pre>
---

ğŸ§¾ Requirements
Python 3.9 or later
ffmpeg installed and in your system PATH (required by Whisper)

---

ğŸ§  Whisper Model Specs
<pre>
Model	Size	Parameters	VRAM Required	Relative Speed	English-only	Multilingual
tiny	~39 MB	39M	~1 GB	~10Ã— faster	âœ… tiny.en	âœ… tiny
base	~74 MB	74M	~1 GB	~7Ã— faster	âœ… base.en	âœ… base
small	~244 MB	244M	~2 GB	~4Ã— faster	âœ… small.en	âœ… small
medium	~769 MB	769M	~5 GB	~2Ã— faster	âœ… medium.en	âœ… medium
large	~1.55 GB	1550M	~10 GB	1Ã— (baseline)	âŒ	âœ… large
turboâ€ 	~809 MB	809M	~6 GB	~8Ã— faster	âŒ	âœ… turbo
</pre>
---

ğŸ“¦ Dependencies (for v1.4.0)

    openai-whisper â€“ core transcription engine

    pyannote-audio â€“ speaker diarization
    â†³ with [pyannote/speaker-diarization-3.1 pipeline](https://huggingface.co/pyannote/speaker-diarization-3.1)**

    mutagen â€“ audio metadata extraction

    ttkbootstrap â€“ modern themed UI for tkinter

    torch, torchaudio, torchvision â€“ GPU support (CUDA 11.8 only)

    ffmpeg â€“ required system dependency (must be installed separately and available in PATH)

    tkinter â€“ included with standard Python installations (â‰¥3.9)

---

ğŸ“ƒ License
MIT License

---

 ğŸ™Œ Acknowledgements

- [OpenAI Whisper](https://github.com/openai/whisper) â€“ for the powerful open-source speech recognition models  
- [pyannote-audio](https://github.com/pyannote/pyannote-audio) â€“ for enabling automated speaker diarization  
- [ttkbootstrap](https://github.com/israel-dryer/ttkbootstrap) â€“ for modern, themeable UI components  
- [PyTorch](https://pytorch.org/) â€“ for the deep learning backend powering both Whisper and Pyannote  
- [FFmpeg](https://ffmpeg.org/) â€“ for robust, cross-platform audio and video processing  